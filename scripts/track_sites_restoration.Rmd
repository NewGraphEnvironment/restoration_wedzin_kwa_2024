---
title: "track sites_restoration.gpkg"
date: "Created: 2024-03-15 | Updated: `r format(Sys.Date(), '%Y-%m-%d')`"
output: 
  html_document:
    code_folding: "hide"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = "100%")

options(scipen=999)
options(knitr.kable.NA = '--') #'--'
options(knitr.kable.NAN = '--')
```

```{r pkgs-load}
library(sf)
library(tidyverse)
```

There is a decent amount of background info that we are converting to spatial files and or combining with other dataset info so we should track what came from where, where it is kept and what it is named. Let's start by reading in the information about `sites_restoration.gpkg` found in the main directory of our collaborative GIS project named `restoration_wedzin_kwa_2023` since we have a few layers in there so can mine that info to get started.

```{r gpkg-read}
path <- "~/Projects/gis/restoration_wedzin_kwa/sites_restoration.gpkg"

# Run the function and assign the output to a list
layers_info <- sf::st_layers(path)

# Extract layer names
layer_names <- layers_info$name

# Loop over the layers and extract the information
gpkg_info_raw <- map_dfr(layer_names, function(layer) {
  data <- sf::st_read(path, layer = layer, quiet = TRUE)
  
  tibble(
    layer_name = layer,
    geometry_type = class(data$geom)[[1]],
    features = nrow(data),
    fields = ncol(data),
    crs_name = st_crs(data)$Name
  )
})


```

<br>



```{r sources-list, eval = TRUE}
# these both were used for sites poly
sites_poly_source <- "~/Library/CloudStorage/OneDrive-Personal/Projects/2024-069-ow-wedzin-kwa-restoration/data/historic_site_info/TreatmentSitesMaster/TreatmentSitesMaster.shp"
sites_poly_source2 <- "~/Library/CloudStorage/OneDrive-Personal/Projects/2024-069-ow-wedzin-kwa-restoration/data/historic_site_info/UB Restoration Site Names.xlsx"


#this was sites_lines
sites_lines_source <- "~/Library/CloudStorage/OneDrive-Personal/Projects/2024-069-ow-wedzin-kwa-restoration/data/historic_site_info/richfield_2021_2022/New Fenceline.shp"

sites_wfn_proposed_source <- "~/zotero/storage/4AAI682C/gaboury_smith_2016_development_of_aquatic_restoration_designs_and_on-farm_cattle_management.pdf"

```

Now we have a dataframe with the information about the layers in the `sites_restoration.gpkg` file. Let's add the information about the gpkg burn it to a csv and and the source for each piece of information by hand.

<br>

Gaboury Smith 2016 was sourced from WFN a few years ago and is stored in shared library on zotero. The other sources are from the 2024-069-ow-wedzin-kwa-restoration project directory shared on onedrive.  We keep reports we reference in our work on `Zotero` because it is a great way to keep track of the literature, insert citations, insert references and it is easy to share with others. 


```{r sources-add}
gpkg_info <- gpkg_info_raw %>% 
  mutate(gpkg_name = 'sites_restoration.gpkg',
         source_path_01 = case_when(
           layer_name == "sites_poly" ~ sites_poly_source,
           layer_name == "sites_lines" ~ sites_lines_source,
           layer_name == "sites_wfn_proposed" ~ sites_wfn_proposed_source,
           TRUE ~ NA_character_
         ),
         source_path_02 = case_when(
           layer_name == "sites_poly" ~ sites_poly_source2,
           TRUE ~ NA_character_),
         # simplify the info for reporting to just be the "location" and "file_name"
         source_location_01 = str_extract(source_path_01, "OneDrive|zotero"),
         source_location_02 = str_extract(source_path_02, "OneDrive|zotero"),
         source_filename_01 = basename(source_path_01),
         source_filename_02 = basename(source_path_02),
         source_description_01 = case_when(
           layer_name == "sites_poly" ~ "Provided by Adam Wrench in 2024 - includes HWI and MWMT sites.",
           layer_name == "sites_lines" ~ "Provided by Adam Wrench in 2023 - includes SERNbc fencing locations.",
           layer_name == "sites_wfn_proposed" ~ "Provided by Wet'suwet'en First Nation in 2021. Includes all sites proposed by Gaboury and Smith in 2016 report.",
           TRUE ~ NA_character_
         ),
         source_description_02 = case_when(
           layer_name == "sites_poly" ~ "Provided by Laura from MWMT in 2024 - includes some tracking of historic nameing.",
           TRUE ~ NA_character_
         )
  )
  
```

<br>

Ok.  A bit of a pain but a good start and in a format that we can see raw on github and import and wrangle within
our reporting later.  Let's burn it out and commit to the repo [here](https://github.com/NewGraphEnvironment/restoration_wedzin_kwa_2024/blob/main/data/sites_restoration_gpkg_tracking.csv).

```{r csv-burn, eval=FALSE}
gpkg_info %>% 
  write_csv(na = "",
            file = "../data/sites_restoration_gpkg_tracking.csv")
```

<br>


In order to render this memo we need a work around from the standard bookdown method. We run this command below
by hand in the console to render the document to a new directory called `memos`.

```{r render-manual, eval = FALSE}
rmarkdown::render("scripts/track_sites_restoration.Rmd", output_file = "track_sites_restoration.html", output_dir = "memos")

```

